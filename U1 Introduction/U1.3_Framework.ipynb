{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical framework\n",
    "\n",
    "Every sentence $y$ from a target language is considered as a possible translation of a given sentence $x$ from a source language\n",
    "\n",
    "For each possible pair of sentences $(x, y)$, there is a probability $P(y \\mid x)$\n",
    "\n",
    "It is expected that $P(y \\mid x)$ is higher for those pairs that are mutual translations\n",
    "\n",
    "The translation model provides $P(y \\mid x)$ for each pair $(x, y)$\n",
    "\n",
    "$P(y \\mid x)$ can be learnt from parallel text: Data-driven approach\n",
    "\n",
    "Inference process as a search of the most probable translation $\\hat{y}$ for a given source sentence $x$: \n",
    "\n",
    "$$\\hat{y} = \\operatorname*{argmax}_{y} P(y \\mid x)$$\n",
    "\n",
    "Source sentence $x$ comes as text in MT. When it comes as a speech signal, then *speech translation (ST)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical approaches\n",
    "\n",
    "$P(y \\mid x)$ is known as the direct (discriminative) approach: log-linear models, neural models, etc.\n",
    "\n",
    "\n",
    "When $P(y \\mid x)$ is rewritten in\n",
    "\n",
    "$$\\hat{y} = \\operatorname*{argmax}_{y} P(x \\mid y) \\, P(y)$$\n",
    "\n",
    "This is known as the generative approach: word-based and some phrase-based models\n",
    "\n",
    "\n",
    "Alternatively, it can be rewritten as a joint probability in finite-state transducers\n",
    "\n",
    "$$\\hat{y} = \\operatorname*{argmax}_{y} P(x, y)$$\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
