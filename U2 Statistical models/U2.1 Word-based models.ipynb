{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning from data\n",
    "\n",
    "<ul>\n",
    "<li><b>Monolingual data</b></li>\n",
    "    Ex.: Mary did not slap the green witch.\n",
    "<li><b>Multilingual data</b></li>\n",
    "    Ex.: Mary did not slap the green witch. Mary no dió una botefada a la bruja verde.\n",
    "<li><b>Parallel data</b></li>\n",
    "<ul>\n",
    "<li><b>Text-To-Text.</b></li>\n",
    "    Ex.: Mary did not slap the green witch. <b>||</b> Mary no dió una botefada a la bruja verde.\n",
    "<li><b>Speech-To-Text.</b> Automatic speech recognition or speech translation</li> \n",
    "<li><b>Text-To-Speech.</b> Speech synthesis</li>\n",
    "<li><b>Speech-To-Speech</b></li>\n",
    "</ul>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning from parallel data: text-to-text\n",
    "\n",
    "Example of parallel text:\n",
    "<table>\n",
    "<tr><td>my house is blue</td><td>nire etxea urdina da</td></tr>\n",
    "<tr><td>my house is white</td><td>nire etxea zuria da</td></tr>\n",
    "<tr><td>my dog was white</td><td>nire txakurra zuria zen</td></tr>\n",
    "<tr><td>the dog was blue</td><td>txakurra urdina zen</td></tr>\n",
    "</table>\n",
    "\n",
    "Exercise: Can you identify which words are mutual translations? That is, define a bilingual dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution:\n",
    "\n",
    "<table>\n",
    "<tr><td>my</td><td>nire</td></tr>\n",
    "<tr><td>house</td><td>etxea</td></tr>\n",
    "<tr><td>is</td><td>da</td></tr>\n",
    "<tr><td>blue</td><td>urdina</td></tr>\n",
    "<tr><td>dog</td><td>txakurra</td></tr>\n",
    "<tr><td>was</td><td>zen</td></tr>\n",
    "<tr><td>the</td><td>NULL</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>The concept of <b>alignment</b> between source and target words naturally arises.</li>\n",
    "<li>If alignments were available, it would be straightforward to derive a bilingual dictionary.</li>\n",
    "<li>Can we automatically learn word alignments from parallel text?</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word-based alignment models\n",
    "\n",
    "\n",
    "Let $x = x_1 \\cdots x_{|x|} = x_1^{|x|}$ and $y = y_1 \\cdots y_{|y|} = y_1^{|y|}$ be source and target sentences that are mutual translations. The variables $x_j$ and $y_i$ denote the $j$-th source word and the $i$-th target word, respectively. For the sake of clarity, let $J=|x|$ and $I=|y|$ be the number of source and target words, respectively.\n",
    "\n",
    "Let $a = a_1 \\cdots a_J$ be an alignment variable that assigns each target position to a source position. That is, $a_j \\in \\{1,\\cdots,I\\}$. For example, in the first sentence above, $a=(1, 2, 4, 3)$.\n",
    "\n",
    "More precisely, a ficticius target position $i=0$ (NULL word) is defined to account for those positions in the source sentence that are not aligned to any target position. Thus, $a_i \\in \\{0, 1,\\cdots,I\\}$. So, the last sentence would be $a=(0, 2, 4, 3)$.\n",
    "\n",
    "The alignment is considered a hidden variable, so that we sum over all its possible values:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "P(x \\mid y) &= \\sum_a P(x, a \\mid y)\\\\%\n",
    "            &= \\sum_a \\prod_j P(x_j, a_j \\mid x, x_1^{j-1}, a_1^{j-1}, x)\\\\%\n",
    "            &= \\sum_a \\prod_j P(x_j \\mid y, x_1^{j-1}, a_1^{j}, x) \\, P(a_j \\mid x, y_1^{j-1}, a_1^{j-1}, x)%\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "### Model 1\n",
    "\n",
    "Assumptions and model parameters:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "P(x_j \\mid y, x_1^{j-1}, a_1^{j}, x)   &:= p(x_j \\mid y_{a_j})\\\\ \n",
    "P(a_j \\mid y, x_1^{j-1}, a_1^{j-1}, x) &:= \\frac{1}{I+1}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Model 1 is defined as:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "P(x \\mid y) &\\approx \\sum_a \\prod_j \\frac{1}{I+1} \\, p(x_j \\mid y_{a_j})\\\\%\n",
    "            &=       \\prod_j \\sum_{a_j} \\frac{1}{I+1} \\, p(x_j \\mid y_{a_j})\\\\%\n",
    "            &= \\frac{1}{(I+1)^J} \\, \\prod_j \\sum_{a_j} p(x_j \\mid y_{a_j})\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Parameter optimization of log-likelihood by EM algorithm:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{E step}: a_{nji} &= \\frac{p(x_{nj} \\mid y_{ni})}{\\sum_{i'} p(x_{nj} \\mid y_{ni'})}\\\\%\n",
    "\\text{M step}: p(u \\mid v) &\\sim  \\sum_n \\sum_{j:x_{nj}=u} \\sum_{i:y_{ni}=v} a_{nji}\n",
    "\\end{align*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3, 4], [1, 2, 3, 5], [1, 6, 7, 5], [8, 6, 7, 4]]\n",
      "[[1, 2, 3, 4], [1, 2, 5, 4], [1, 6, 5, 7], [6, 3, 7]]\n",
      "M1Dict = [[0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      " [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      " [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      " [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      " [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      " [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      " [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      " [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]]\n",
      "M1Dict = [[0.176 0.134 0.148 0.183 0.183 0.228 0.257 0.16 ]\n",
      " [0.25  0.195 0.217 0.12  0.253 0.139 0.146 0.   ]\n",
      " [0.25  0.276 0.302 0.163 0.168 0.    0.    0.   ]\n",
      " [0.111 0.117 0.123 0.29  0.    0.18  0.189 0.198]\n",
      " [0.25  0.276 0.302 0.163 0.168 0.    0.    0.   ]\n",
      " [0.25  0.138 0.144 0.    0.3   0.162 0.167 0.   ]\n",
      " [0.111 0.    0.    0.146 0.124 0.294 0.327 0.2  ]\n",
      " [0.111 0.    0.    0.146 0.124 0.294 0.327 0.2  ]]\n",
      "M1Dict = [[0.176 0.103 0.11  0.193 0.176 0.235 0.269 0.144]\n",
      " [0.256 0.152 0.163 0.129 0.242 0.151 0.161 0.   ]\n",
      " [0.283 0.27  0.3   0.107 0.197 0.    0.    0.   ]\n",
      " [0.119 0.146 0.157 0.224 0.    0.197 0.212 0.2  ]\n",
      " [0.227 0.192 0.193 0.261 0.243 0.    0.    0.   ]\n",
      " [0.199 0.174 0.186 0.    0.206 0.203 0.216 0.   ]\n",
      " [0.164 0.    0.    0.152 0.172 0.252 0.27  0.173]\n",
      " [0.15  0.    0.    0.219 0.194 0.223 0.228 0.205]]\n",
      "M1Dict = [[0.171 0.089 0.095 0.195 0.164 0.252 0.304 0.135]\n",
      " [0.255 0.135 0.144 0.137 0.233 0.162 0.181 0.   ]\n",
      " [0.304 0.253 0.273 0.118 0.193 0.    0.    0.   ]\n",
      " [0.133 0.167 0.188 0.195 0.    0.188 0.199 0.183]\n",
      " [0.197 0.267 0.288 0.205 0.168 0.    0.    0.   ]\n",
      " [0.226 0.181 0.203 0.    0.249 0.178 0.186 0.   ]\n",
      " [0.152 0.    0.    0.148 0.157 0.272 0.309 0.161]\n",
      " [0.117 0.    0.    0.167 0.132 0.271 0.296 0.22 ]]\n",
      "M1Dict = [[0.17  0.075 0.077 0.215 0.164 0.254 0.309 0.133]\n",
      " [0.259 0.116 0.12  0.15  0.235 0.166 0.186 0.   ]\n",
      " [0.321 0.227 0.235 0.137 0.201 0.    0.    0.   ]\n",
      " [0.145 0.151 0.162 0.219 0.    0.189 0.203 0.177]\n",
      " [0.205 0.261 0.294 0.185 0.207 0.    0.    0.   ]\n",
      " [0.236 0.168 0.179 0.    0.252 0.182 0.192 0.   ]\n",
      " [0.153 0.    0.    0.164 0.158 0.269 0.307 0.156]\n",
      " [0.142 0.    0.    0.171 0.176 0.244 0.246 0.211]]\n",
      "M1Dict = [[0.164 0.069 0.07  0.218 0.156 0.259 0.322 0.135]\n",
      " [0.255 0.109 0.11  0.157 0.225 0.171 0.195 0.   ]\n",
      " [0.327 0.22  0.222 0.143 0.195 0.    0.    0.   ]\n",
      " [0.146 0.148 0.154 0.226 0.    0.191 0.209 0.176]\n",
      " [0.21  0.262 0.285 0.195 0.2   0.    0.    0.   ]\n",
      " [0.239 0.167 0.173 0.    0.247 0.184 0.197 0.   ]\n",
      " [0.147 0.    0.    0.163 0.149 0.274 0.321 0.157]\n",
      " [0.14  0.    0.    0.173 0.166 0.249 0.259 0.209]]\n",
      "M1Dict = [[0.161 0.066 0.067 0.217 0.154 0.26  0.324 0.137]\n",
      " [0.253 0.105 0.106 0.156 0.224 0.172 0.197 0.   ]\n",
      " [0.327 0.215 0.217 0.146 0.196 0.    0.    0.   ]\n",
      " [0.149 0.147 0.153 0.224 0.    0.191 0.209 0.178]\n",
      " [0.21  0.263 0.287 0.194 0.202 0.    0.    0.   ]\n",
      " [0.24  0.166 0.172 0.    0.246 0.184 0.198 0.   ]\n",
      " [0.146 0.    0.    0.162 0.149 0.275 0.321 0.159]\n",
      " [0.143 0.    0.    0.175 0.17  0.247 0.255 0.208]]\n",
      "M1Dict = [[0.159 0.065 0.065 0.217 0.152 0.261 0.326 0.139]\n",
      " [0.251 0.103 0.104 0.157 0.223 0.174 0.199 0.   ]\n",
      " [0.329 0.212 0.214 0.146 0.196 0.    0.    0.   ]\n",
      " [0.149 0.146 0.152 0.225 0.    0.191 0.209 0.179]\n",
      " [0.211 0.264 0.288 0.192 0.201 0.    0.    0.   ]\n",
      " [0.24  0.165 0.171 0.    0.247 0.184 0.198 0.   ]\n",
      " [0.145 0.    0.    0.162 0.148 0.276 0.323 0.161]\n",
      " [0.144 0.    0.    0.174 0.17  0.247 0.255 0.208]]\n",
      "M1Dict = [[0.158 0.064 0.064 0.217 0.151 0.262 0.327 0.14 ]\n",
      " [0.25  0.102 0.102 0.157 0.222 0.174 0.199 0.   ]\n",
      " [0.33  0.211 0.212 0.147 0.196 0.    0.    0.   ]\n",
      " [0.15  0.145 0.151 0.225 0.    0.191 0.209 0.179]\n",
      " [0.211 0.264 0.288 0.193 0.202 0.    0.    0.   ]\n",
      " [0.241 0.164 0.17  0.    0.247 0.184 0.198 0.   ]\n",
      " [0.144 0.    0.    0.161 0.147 0.276 0.324 0.162]\n",
      " [0.145 0.    0.    0.175 0.171 0.247 0.254 0.208]]\n",
      "M1Dict = [[0.158 0.063 0.064 0.217 0.151 0.262 0.328 0.141]\n",
      " [0.25  0.101 0.102 0.157 0.221 0.175 0.2   0.   ]\n",
      " [0.33  0.21  0.211 0.147 0.195 0.    0.    0.   ]\n",
      " [0.15  0.145 0.15  0.225 0.    0.191 0.209 0.18 ]\n",
      " [0.212 0.265 0.288 0.192 0.202 0.    0.    0.   ]\n",
      " [0.241 0.164 0.169 0.    0.247 0.184 0.198 0.   ]\n",
      " [0.144 0.    0.    0.161 0.147 0.276 0.324 0.162]\n",
      " [0.145 0.    0.    0.175 0.171 0.247 0.254 0.208]]\n",
      "M1Dict = [[0.157 0.063 0.063 0.217 0.15  0.262 0.328 0.141]\n",
      " [0.249 0.1   0.101 0.157 0.221 0.175 0.2   0.   ]\n",
      " [0.33  0.209 0.211 0.147 0.195 0.    0.    0.   ]\n",
      " [0.15  0.145 0.15  0.225 0.    0.191 0.209 0.18 ]\n",
      " [0.212 0.265 0.288 0.192 0.202 0.    0.    0.   ]\n",
      " [0.241 0.164 0.169 0.    0.247 0.184 0.198 0.   ]\n",
      " [0.144 0.    0.    0.161 0.147 0.276 0.324 0.162]\n",
      " [0.146 0.    0.    0.175 0.171 0.247 0.254 0.208]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "def create_dataset(sents):\n",
    "    dict = {}\n",
    "    idSents = []\n",
    "    id = 1\n",
    "    for sent in sents:\n",
    "        idSent = []\n",
    "        for word in sent.split():\n",
    "            if word not in dict:\n",
    "                dict[word] = id\n",
    "                idSent.append(id)\n",
    "                id += 1                 \n",
    "            else:\n",
    "                idSent.append(dict[word])\n",
    "        idSents.append(idSent)\n",
    "    return dict, idSents\n",
    "    \n",
    "srcSents = ['my house is blue','my house is white','my dog was white','the dog was blue']\n",
    "trgSents = ['nire etxea urdina da','nire etxea zuria da','nire txakurra zuria zen','txakurra urdina zen']\n",
    "\n",
    "srcDict, srcData = create_dataset(srcSents)\n",
    "trgDict, trgData = create_dataset(trgSents)\n",
    "\n",
    "print(srcData)\n",
    "print(trgData)\n",
    "\n",
    "# M1 dictionary initialise with uniform distro\n",
    "M1Dict = np.zeros((len(trgDict)+1,len(srcDict)),dtype=float)\n",
    "for trgWord in range(len(M1Dict)):\n",
    "    M1Dict[trgWord] = 1.0/len(srcDict)\n",
    "print(f'M1Dict = {M1Dict}')\n",
    "\n",
    "\n",
    "for iter in range(10):\n",
    "    newM1Dict = np.zeros((len(trgDict)+1,len(srcDict)),dtype=float)\n",
    "    for n in range(len(srcData)): \n",
    "        # E-step\n",
    "        a = np.zeros((len(srcData[n]), len(trgData[n])+1),dtype=float)\n",
    "        for j in range(len(srcData[n])):\n",
    "            # NULL word\n",
    "            a[j][0] = M1Dict[0][srcData[n][j]-1]\n",
    "            suma = a[j][0]\n",
    "            for i in range(len(trgData[n])):\n",
    "                a[j][i+1] = M1Dict[trgData[n][i]][srcData[n][j]-1]\n",
    "                suma += a[j][i+1]\n",
    "            #print(f'a =\\n{a}')\n",
    "            a[j][0] /= suma\n",
    "            for i in range(len(trgData[n])):\n",
    "                a[j][i+1] /= suma\n",
    "        # M-step\n",
    "        for j in range(len(srcData[n])):\n",
    "            newM1Dict[0][srcData[n][j]-1] += a[j][0]\n",
    "            for i in range(len(trgData[n])):\n",
    "                newM1Dict[trgData[n][i]][srcData[n][j]-1] += a[j][i]\n",
    "        #print(f'newM1Dict = {newM1Dict}')\n",
    "\n",
    "    # Normalise to obtain probabilities\n",
    "    for trgWord in range(len(M1Dict)):\n",
    "        for srcWord in range(len(M1Dict[trgWord])):\n",
    "            newM1Dict[trgWord][srcWord] /= np.sum(newM1Dict[trgWord])\n",
    "\n",
    "    # Update M1 dictionary\n",
    "    M1Dict = newM1Dict\n",
    "    print(f'M1Dict = {M1Dict}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other word-based models\n",
    "\n",
    "<ul>\n",
    "<li>IBM research group proposed models 1 through 5</li>\n",
    "<li>HMM alignment model</li>\n",
    "<li>Mixture models</li>\n",
    "<li>etc.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional bibliography\n",
    "\n",
    "<ul>\n",
    "<li><a href=\"https://kevincrawfordknight.github.io/papers/wkbk-rw.pdf\" target=\"_blank\">K. Knight. A Statistical MT Tutorial Workbook, August 1999.</a></li>\n",
    "<li><a href=\"https://github.com/moses-smt/giza-pp\" target=\"_blank\">F. Och. GIZA++ toolkit and the mkcls tool.</a></li>\n",
    "</ul>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
