{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Machine Translation\n",
    "\n",
    "From LM to MT: from monolingual to cross-lingual word prediction\n",
    "\n",
    "Early proposals with syncronized RNN [1]\n",
    "\n",
    "Non-syncronized RNN: Encoder-Decoder architecture [2]\n",
    "\n",
    "<img src=\"Sutskever2014_EncoderDecoder.svg\" width=\"1000\"/>\n",
    "\n",
    "A source LM (encoder) whose hidden state is transfered to a target LM (decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: node 'a1', graph '%3' size too small for label\n",
      "Warning: node 'e1', graph '%3' size too small for label\n",
      "Warning: node 'e2', graph '%3' size too small for label\n",
      "Warning: node 'a5', graph '%3' size too small for label\n",
      "Warning: node 'e6', graph '%3' size too small for label\n",
      "Warning: node 'a9', graph '%3' size too small for label\n",
      "Warning: node 'e10', graph '%3' size too small for label\n"
     ]
    }
   ],
   "source": [
    "import graphviz as G\n",
    "\n",
    "# boolean variables to denote dense or sparse connections between layers\n",
    "DENSE = True\n",
    "SPARSE = False\n",
    "\n",
    "\n",
    "TIMESTEPS = 11\n",
    "TIME_OFFSET = 3\n",
    "words=['&lt;s&gt;','the','house','is','blue','.','&lt;/s&gt;','la','casa','es','blanca','&lt;/s&gt;']\n",
    "\n",
    "unrolled = G.Digraph(node_attr={'shape':'circle', 'fixedsize':'true'}, graph_attr={'style':'invis', 'rankdir':'BT', 'color':'transparent'})\n",
    "\n",
    "i=0\n",
    "for step in range(TIMESTEPS+2):\n",
    "    if step == 0 or step == TIMESTEPS+1:\n",
    "        with unrolled.subgraph(name='cluster_'+str(i)) as c:\n",
    "            c.node('a'+str(step), '', color='transparent')\n",
    "            c.node('b'+str(step), '', color='transparent')\n",
    "            c.node('c'+str(step), '', color='transparent') \n",
    "            c.node('d'+str(step), '', color='transparent')\n",
    "            c.edge('a'+str(step), 'b'+str(step), style='invis') \n",
    "            c.edge('b'+str(step), 'c'+str(step), style='invis')\n",
    "            c.edge('c'+str(step), 'd'+str(step), style='invis')\n",
    "    else:\n",
    "        with unrolled.subgraph(name='cluster_'+str(i)) as c:\n",
    "            c.node('a'+str(step), words[TIMESTEPS-step], color='transparent');\n",
    "            c.node('b'+str(step), 'WE')\n",
    "            #c.node('c'+str(step), 't'+'{:=+d}'.format(TIME_OFFSET-step) if TIME_OFFSET-step else 't')\n",
    "            c.node('c'+str(step), '')\n",
    "            c.node('d'+str(step), 'SM');\n",
    "            #c.node('e'+str(step), '<w<sub>'+'t'+'{:=+d}'.format(TIME_OFFSET-step+1)+'</sub>>' if TIME_OFFSET-step+1 else '<w<sub>'+'t'+'</sub>>', color='transparent');\n",
    "            c.node('e'+str(step), words[TIMESTEPS-step+1], color='transparent');\n",
    "            c.edge('a'+str(step), 'b'+str(step), label='<w<sub>'+'t'+'{:=+d}'.format(TIME_OFFSET-step)+'</sub>>' if TIME_OFFSET-step else '<w<sub>'+'t'+'</sub>>'); \n",
    "            c.edge('b'+str(step), 'c'+str(step), label='<e<sub>'+'t'+'{:=+d}'.format(TIME_OFFSET-step)+'</sub>>' if TIME_OFFSET-step else '<e<sub>'+'t'+'</sub>>'); \n",
    "            c.edge('c'+str(step), 'd'+str(step), label='<h<sub>'+'t'+'{:=+d}'.format(TIME_OFFSET-step)+'</sub>>' if TIME_OFFSET-step else '<h<sub>'+'t'+'</sub>>');\n",
    "            c.edge('d'+str(step), 'e'+str(step), label='<y<sub>'+'t'+'{:=+d}'.format(TIME_OFFSET-step+1)+'</sub>>' if TIME_OFFSET-step+1 else '<y<sub>'+'t'+'</sub>>');\n",
    "            \n",
    "for step in range(1, TIMESTEPS+1):\n",
    "    unrolled.edge('c'+str(step-1), 'c'+str(step), label='<s<sub>'+'t'+'{:=+d}'.format(TIME_OFFSET-step)+'</sub>>' if TIME_OFFSET-step else '<s<sub>'+'t'+'</sub>>', constraint='false', dir='back', color='black')\n",
    "\n",
    "unrolled.render(filename='RNNMT', format='svg');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a source sentence $x_1^J$ search for a target sentence\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat{y}_1^{\\hat{I }} &= \\argmax_{y_1^I} P(y_1^I\\mid x_1^J)\\\\\n",
    "                     &= \\argmax_{y_1^I} \\prod_{i=1}^I p(y_i\\mid y_1^{i-1},x_1^J)\\\\\n",
    "                     &= \\argmax_{y_1^I} \\prod_{i=1}^I p(y_i\\mid y_1^{i-1},c(x_1^J))\n",
    "\\end{align}\n",
    "$$\n",
    "where $u(x_1^J)$ is a hidden-state representation of $x_1^J$.\n",
    "\n",
    "Search for the most likely translation using a simple left-to-right beam search decoder\n",
    "\n",
    "At each timestep each partial hypothesis (prefix translations) is extended with every word in the vocabulary.\n",
    "\n",
    "A small number $B$ of most-probable partial hypotheses are mantained\n",
    "\n",
    "When the symbol &lt;s&gt; appears in a hypothesis, it is considered to be complete\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results on WMT14 English-to-French [2]:\n",
    "\n",
    "|Systems|BLEU|\n",
    "|:------|---:|\n",
    "|Baseline (PB+Neural LM) | 33.3|\n",
    "|Ensemble of 5 LSTMs | 34.8|\n",
    "|Reescoring 1000-best with ensemble of 5 LSTMs | 36.5|\n",
    "|Moses for WMT14 | 37.0 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN with attention (Bahdanau et al.) [3]\n",
    "\n",
    "Conventional RNN *squash* all the source sentence information into a fixed-length vector\n",
    "\n",
    "RNN tend to to better represent recent inputs\n",
    "\n",
    "RNN with attention encode the input sentence into a sequence of vectors $h_1^J$ \n",
    "\n",
    "They select a subset of these vectors $h_1^J$ adaptively (attention mechanism) while decoding\n",
    "\n",
    "$$\n",
    "\\hat{y}_1^{\\hat{I }} = \\argmax_{y_1^I} \\prod_{i=1}^I p(y_i\\mid y_1^{i-1},c_i)\n",
    "$$\n",
    "where\n",
    "$$\n",
    "c_i = \\sum_{j=1}^{J} \\alpha_{ij} h_j\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\alpha_{ij} = \\frac{\\exp(a_{ij})}{\\sum_{k=1}^{J} \\exp(a_{ik})}\n",
    "$$\n",
    "being\n",
    "$$\n",
    "a_{ij} = v_a^t \\tanh \\left( W_a h_{i-1} + U_a h_j \\right)\n",
    "$$\n",
    "where $v_a \\in \\mathbb{R}$, $W_a \\in \\mathbb{R}^{n \\times n}$ and $U_a \\in \\mathbb{R}^{n \\times 2n}$\n",
    "\n",
    "Consequently, the hidden state of the RNN decoder $h_i$ is enriched with $c_i$ as\n",
    "$$\n",
    "h_i = f(h_{i-1}, y_{i−1}, c_i)\n",
    "$$\n",
    "and the output layer computing the probability over the vocabulary also incorporates $c_i$ and the residual connection $y_{i-1}$ \n",
    "$$\n",
    "p(y_i\\mid y_1^{i-1},c_i) = g(h_i, y_{i−1}, c_i)\n",
    "$$\n",
    "Indeed, the RNN hidden state at the encoder $h_j$ is the concatenation of the hidden state of a forward and a backward RNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Bahdanau2015_EncoderDecoder.svg\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN with attention (Luong et al.) [4]\n",
    "\n",
    "Simplification and generalisation over [3]\n",
    "\n",
    "  * Unidirectional encoder\n",
    "  * Alternative attention mechanism: $ a_{ij} = \\left\\{ \\begin{matrix} h_i^t \\, h_j\\\\h_i^t \\, W_a \\, h_j\\\\ W_a \\, [h_i;h_j]  \\end{matrix} \\right.$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Luong2015_EncoderDecoder.svg\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All in all, in 2014, NMT systems still behind SOTA phrase-based systems "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Is All You Need [5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional bibliography\n",
    "\n",
    "<ol>\n",
    "<li><a href=\"https://www.isca-archive.org/eurospeech_1997/castano97_eurospeech.pdf\" target=\"_blank\">M.A. Castaño and F. Casacuberta. A Connectionist Approach to Machine Translation, EuroSpeech 1997.</a></li>\n",
    "<li><a href=\"https://papers.nips.cc/paper_files/paper/2014/file/a14ac55a4f27472c5d894ec1c3c743d2-Paper.pdf\" target=\"_blank\">I. Sutskever et al. Sequence to Sequence Learning with Neural Networks, NIPS 2014.</a></li>\n",
    "<li><a href=\"https://arxiv.org/pdf/1409.0473\" target=\"_blank\">D. Bahdanau et al. Neural Machine Translation by Jointly Learning to Align and Translate, ICLR 2015.</a></li>\n",
    "<li><a href=\"https://aclanthology.org/D15-1166.pdf\" target=\"_blank\">M. Luong et al. Effective Approaches to Attention-based Neural Machine Translation, EMNLP 2015.</a></li>\n",
    "<li><a href=\"https://arxiv.org/pdf/1706.03762\" target=\"_blank\">A. Vaswani et al. Attention Is All You Need, NIPS 2017.</a></li>\n",
    "</ol>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_tfcuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
